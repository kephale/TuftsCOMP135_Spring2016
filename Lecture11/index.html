<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>Introduction to Machine Learning and Data Mining</title>

    <meta name="description" content="Introduction to Machine Learning and Data Mining">
    <meta name="author" content="Kyle I S Harrington">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/black_KISHtufts135_2016.css" id="theme">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!-- Mermaid
    <link rel="stylesheet" href="css/mermaid.css">
    <script src="js/mermaid.slim.js"></script> -->

    <!-- Footer header
    <link rel="stylesheet" href="plugin/title-footer/title-footer.css"> -->

    <!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
  </head>

  <body>
    <div class="reveal">
      <div class="footer">
	Tufts University - <a href="http://www.cs.tufts.edu/comp/135/">COMP 135</a> - Spring 2016 / Kyle I S Harrington
      </div>

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
	<section>
	  <h2>Introduction to Machine Learning and Data Mining</h2>
    <br><br><br>
    <h3>Neurocomputing</h3>
	  <p>
	    <small> <a href="http://kyleharrington.com">Kyle I S Harrington</a> / <a href="mailto:kyle@eecs.tufts.edu">kyle@eecs.tufts.edu</a></small>
	  </p>
	  <br><br><br><br><br><br>
    <small>Some slides adapted from Geoffrey Hinton, UToronto; Tommi Jaakola, MIT.</small>
	</section>


  <section>
    <h2>Starting with Neuroscience</h2>
    <img src="https://upload.wikimedia.org/wikipedia/commons/1/15/PurkinjeCell.jpg" width=40%>
    <small>Drawing of Purkinje cells (A) and granule cells (B) from pigeon cerebellum by Santiago Ram√≥n y Cajal, 1899; Instituto Cajal, Madrid, Spain. Public domain.</small>
	</section>

  <section>
    <h2>Linear Threshold Units</h2>
    <p><img src="http://cse-wiki.unl.edu/wiki/images/f/f4/Linearthresholdunit_mkrause.png" width=45%></p>
    <small>Image from Margaret Krause, UNL.</small>
  </section>

<section>
<section>
  <h2>From Growth to Learning</h2>
  <p>Hebb's learning rule: fire together, wire together</p>
  <br><br><br><br><br><br><br><br><br>
</section>


<section>
  <h2>Hebbian Learning</h2>
  <p>$\Delta w_{kj} = \eta x_j y_k$</p>
  <p>change weight $i$ proportinally to the product of the input and the output</p>
  <br><br><br><br><br><br><br><br><br>
</section>

<section>
  <h2>Hebbian Learning</h2>
  <p>$\Delta w_{kj} = \eta x_j y_k$</p>
  <p>Problems?</p>
  <br><br><br><br><br><br><br><br><br>
</section>

</section>


<section>

  <section>
  <h2>Supervised Method</h2>
  <p>How do we find weights that can produce a particular output?</p>
  <br><br><br><br><br><br><br><br><br>
  </section>

<section>
<h2>Hinton's Fish and Chips</h2>
<ul>
  <li>Diet of multiple portions of fish, chips, and ketchup</li>
  <li>Cashier only gives total price of meal</li>
</ul>
<br><br><br><br><br><br><br><br><br>
</section>

<section>
<h2>Hinton's Fish and Chips</h2>
<ul>
  <li>Start with random guesses for the price of each portion</li>
  <li>After multiple days, should be able to know prices of individual portions</li>
</ul>
<br><br><br><br><br><br><br><br><br>
</section>

<section>
<h2>Delta-rule</h2>
<p>$\Delta w_{kj} = \eta ( t_k - o_k ) i_k$</p>
<br><br><br><br><br><br><br><br><br>
</section>

</section>

<section>
  <section>
  <h2>Gradient Descent</h2>
    <p>

      <img width=30%  src="images/Gradient_descent_edited.svg">

    <!--  <img width=30% src="https://upload.wikimedia.org/wikipedia/commons/f/ff/Gradient_descent.svg"> -->
    </p>
    <p align="left">
      start with some $w_{(0)}$ <br>
      do:<br>
        &nbsp;&nbsp;&nbsp;&nbsp; $w^{(t+1)} = w^{(t)} - \eta_t \nabla F(w^{(t)})$<br>
        until $||w^{(t+1)}-w^{(t)}|| \leq \epsilon$
    </p>
  </section>

  <section>
  <h2>Learning Rate</h2>
  $w^{(t+1)} = w^{(t)} - \eta_t \nabla F(w^{(t)})$
  <p><img width=45% src="https://www.willamette.edu/~gorr/classes/cs449/figs/jen/musmall.gif"><img width=45% src="https://www.willamette.edu/~gorr/classes/cs449/figs/jen/mularge.gif"></p>
  <small>Images from <a href="https://www.willamette.edu/~gorr/classes/cs449/precond.html">Genevieve Orr</a></small>
  </section>

  <section>
  <h2>Stochastic Gradient Descent</h2>
  <p>Given a stream of input/output samples</p>
  <p>Update weights after each sample (online learning)</p>
  </section>

  <section>
  <h2>Stochastic Gradient Descent</h2>
  <p>Notebook!</p>
  </section>
</section>

<section>
  <section>
  <h2>Binary Classification</h2>
  <p>Predict a binary class, $y$, given a feature value, $x$</p>
  <p>$P(y=1|x) > P(y=0|x)$</p>
  </section>

  <section>
  <h2>Log-odds Ratio</h2>
  <p>Rewrite $P(y=1|x) > P(y=0|x)$</p>
  <p>As log-odds: $log \frac{P(y=1|\textbf{x})}{P(y=0|\textbf{x})} > 0$</p>
  </section>

  <section>
  <h2>Log-odds Ratio</h2>
  <p>$P(y|\textbf{x})$ is generally either unknown or estimated from samples</p>
  <p>Linear approximation $log \frac{P(y=1|\textbf{x})}{P(y=0|\textbf{x})}$ as</p>
  <p>$f(x;w) = w_o + x \cdot w_1$</p>
  </section>

  <section>
  <h2>Log-odds to Sigmoid</h2>
  <p>$log \frac{P(y=1|\textbf{x})}{P(y=0|\textbf{x})} = w_o + x \cdot w_1$</p>
  <!-- <p>$log \frac{P(y=1|\textbf{x})}{(1-P(y=1|\textbf{x}))} = w_o + x^T w_1$</p> -->
  <p>Instead we use</p>
  <p>$P(y=1|x_i, w_{0,i} , w_{1,i} ) = g( w_{0,i} + x \cdot w_{1,i} )$</p>
  <p>$g(z) = \frac{1}{(1+e^{-z})}$</p>
  </section>

  <section>
  <h2>Logistic Function</h2>
  <p>"Squishing function"</p>
  <p>$f(x) = \frac{1}{1+e^{-x}}$</p>
  <img src="images/logistic_function.png">
  </section>


  </section>

<section>
  <section>
  <h2>Regularization</h2>
  <p>Learn the weights with a penalty, $w$:</p>
  <p>$\text{argmax}_{w} \displaystyle \sum^m_{i=1} P(y_i=1|x_i, w ) - \alpha R(w) $</p>
  </section>

  <section>
  <h2>Regularization Term</h2>
  <p>Regularization term, $R(w)$, forces parameters to be small when $\alpha>0$</p>
  <p>L1: $R(w) = ||w||_1 = \displaystyle \sum^n_{i=1} |w_i|$</p>
  <p>L2: $R(w) = ||w||_2 = \displaystyle \sum^n_{i=1} w_i^2$</p>
  <small>L2 tends to be better at shrinking weights</small>
  </section>


  </section>
<!--  <small>Based on <a href="http://www.ai.mit.edu/courses/6.867-f04/lectures/lecture-5.pdf">slides</a> by Tommi Jaakola, MIT.</small> -->







  </section>

  <section>
    <h2>Final Project Proposal</h2>
    <p>Due March 7 (Monday)</p>
    <p><a href="https://github.com/kephale/complexfeaturesbcell/blob/master/Proposal.md">An example proposal</a></p>
  </section>

 	<section>
	  <h2>What Next?</h2>
    <p>Clustering</p>
	</section>
      </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
      controls: true,
      progress: true,
      history: true,
      center: true,

      transition: 'slide', // none/fade/slide/convex/concave/zoom

      // Optional reveal.js plugins
      dependencies: [
      { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
      { src: 'plugin/zoom-js/zoom.js', async: true },
      { src: 'plugin/notes/notes.js', async: true },
      { src: 'plugin/math/math.js', async: true }
      ]
      });

//      { src: 'plugin/mermaid/mermaid.js' }
    </script>

  </body>
</html>
